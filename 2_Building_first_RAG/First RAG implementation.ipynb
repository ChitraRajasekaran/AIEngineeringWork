{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91af1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1: Imports and Utility - We're just doing some imports and enabling async to work within the Jupyter environment here, nothing too crazy!\n",
    "#!pip install -qU numpy matplotlib plotly pandas scipy scikit-learn openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d18c798-55f7-4f60-92fc-30837d71524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text_utils import TextFileLoader, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99c141b-41f0-450c-8198-170e0038cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vectordatabase import VectorDatabase\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557c6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d594a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2: Documents\n",
    "\n",
    "# Loading Source Documents\n",
    "\n",
    "# So, first things first, we need some documents to work with.\n",
    "\n",
    "# While we could work directly with the .txt files (or whatever file-types you wanted to extend this to) we can instead do some batch processing of those documents at the beginning in order to store them in a more machine compatible format.\n",
    "\n",
    "# In this case, we're going to parse our text file into a single document in memory.\n",
    "\n",
    "# Let's look at the relevant bits of the TextFileLoader class:\n",
    "\n",
    "# def load_file(self):\n",
    "#         with open(self.path, \"r\", encoding=self.encoding) as f:\n",
    "#             self.documents.append(f.read())\n",
    "\n",
    "# We're simply loading the document using the built in open method, \n",
    "#and storing that output in our self.documents list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe70b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_loader = TextFileLoader(\"data/kingLear.txt\")\n",
    "documents = text_loader.load_documents()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7944e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606\n",
      "THE TRAGEDY OF KING LEAR\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dramatis Personae\n",
      "\n",
      "      Lear, King of Bri\n"
     ]
    }
   ],
   "source": [
    "print(documents[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4478c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Text Into Chunks\n",
    "\n",
    "# As we can see, there is one massive document.\n",
    "\n",
    "# We'll want to chunk the document into smaller parts so it's easier to pass the most relevant snippets to the LLM.\n",
    "\n",
    "# There is no fixed way to split/chunk documents - and you'll need to rely on some intuition as well as knowing your data very well in order to build the most robust system.\n",
    "\n",
    "# For this toy example, we'll just split blindly on length.\n",
    "\n",
    "#     There's an opportunity to clear up some terminology here, for this course we will be stick to the following:\n",
    "\n",
    "#         \"source documents\" : The .txt, .pdf, .html, ..., files that make up the files and information we start with in its raw format\n",
    "#         \"document(s)\" : single (or more) text object(s)\n",
    "#         \"corpus\" : the combination of all of our documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4026d40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter()\n",
    "split_documents = text_splitter.split_texts(documents)\n",
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc913315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at some of the documents we've managed to split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "022ea219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"1606\\nTHE TRAGEDY OF KING LEAR\\n\\nby William Shakespeare\\n\\n\\n\\n\\nDramatis Personae\\n\\n      Lear, King of Britain.\\n      King of France.\\n      Duke of Burgundy.\\n      Duke of Cornwall.\\n      Duke of Albany.\\n      Earl of Kent.\\n      Earl of Gloucester.\\n      Edgar, son of Gloucester.\\n      Edmund, bastard son to Gloucester.\\n      Curan, a courtier.\\n      Old Man, tenant to Gloucester.\\n      Doctor.\\n      Lear's Fool.\\n      Oswald, steward to Goneril.\\n      A Captain under Edmund's command.\\n      Gentlemen.\\n      A Herald.\\n      Servants to Cornwall.\\n\\n      Goneril, daughter to Lear.\\n      Regan, daughter to Lear.\\n      Cordelia, daughter to Lear.\\n\\n      Knights attending on Lear, Officers, Messengers, Soldiers,\\n        Attendants.\\n\\n\\n\\n\\n<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\\nSHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\\nPROVIDED BY PROJECT GUTENBERG ETEXT OF CARNEGIE MELLON UNIVERSITY\\nWITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\\nDISTRIBUT\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_documents[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ceedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Task 3: Embeddings and Vectors\n",
    "\n",
    "# Next, we have to convert our corpus into a \"machine readable\" format \n",
    "\n",
    "# we're going to see the actual process of creating, and then storing, \n",
    "# these embeddings, and how we can leverage that to intelligently add context to our queries.\n",
    "# OpenAI API Key\n",
    "\n",
    "# In order to access OpenAI's APIs, we'll need to provide our OpenAI API Key!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9171d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7797ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vector Database\n",
    "\n",
    "# Let's set up our vector database to hold all our documents and their embeddings!\n",
    "\n",
    "# While this is all baked into 1 call - we can look at some of the code that powers this process to get a better understanding:\n",
    "\n",
    "# Let's look at our VectorDatabase().__init__():\n",
    "\n",
    "# def __init__(self, embedding_model: EmbeddingModel = None):\n",
    "#         self.vectors = defaultdict(np.array)\n",
    "#         self.embedding_model = embedding_model or EmbeddingModel()\n",
    "\n",
    "# As you can see - our vectors are merely stored as a dictionary of np.array objects.\n",
    "\n",
    "# Secondly, our VectorDatabase() has a default EmbeddingModel() which is a wrapper for OpenAI's text-embedding-3-small model.\n",
    "\n",
    "#     Quick Info About text-embedding-3-small:\n",
    "\n",
    "#         It has a context window of 8191 tokens\n",
    "#         It returns vectors with dimension 1536\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3d71e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We can call the async_get_embeddings method of our EmbeddingModel() on a list of str and receive a list of float back!\n",
    "\n",
    "# async def async_get_embeddings(self, list_of_text: List[str]) -> List[List[float]]:\n",
    "#         return await aget_embeddings(\n",
    "#             list_of_text=list_of_text, engine=self.embeddings_model_name\n",
    "#         )\n",
    "\n",
    "# We cast those to np.array when we build our VectorDatabase():\n",
    "\n",
    "# async def abuild_from_list(self, list_of_text: List[str]) -> \"VectorDatabase\":\n",
    "#         embeddings = await self.embedding_model.async_get_embeddings(list_of_text)\n",
    "#         for text, embedding in zip(list_of_text, embeddings):\n",
    "#             self.insert(text, np.array(embedding))\n",
    "#         return self\n",
    "\n",
    "# And that's all we need to do!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "609036ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = VectorDatabase()\n",
    "vector_db = asyncio.run(vector_db.abuild_from_list(split_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74591c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# So, to review what we've done so far in natural language:\n",
    "\n",
    "#     We load source documents\n",
    "#     We split those source documents into smaller chunks (documents)\n",
    "#     We send each of those documents to the text-embedding-3-small OpenAI API endpoint\n",
    "#     We store each of the text representations with the vector representations as keys/values in a dictionary\n",
    "\n",
    "# Semantic Similarity\n",
    "\n",
    "# The next step is to be able to query our VectorDatabase() with a str and have it return to us vectors and text that is most relevant from our corpus.\n",
    "\n",
    "# We're going to use the following process to achieve this in our toy example:\n",
    "\n",
    "#     We need to embed our query with the same EmbeddingModel() as we used to construct our VectorDatabase()\n",
    "#     We loop through every vector in our VectorDatabase() and use a distance measure to compare how related they are\n",
    "#     We return a list of the top k closest vectors, with their text representations\n",
    "\n",
    "# There's some very heavy optimization that can be done at each of these steps - but let's just focus on the basic pattern in this notebook.\n",
    "\n",
    "#     We are using cosine similarity as a distance metric in this example - but there are many many distance metrics you could use - like these\n",
    "\n",
    "#     We are using a rather inefficient way of calculating relative distance between the query vector and all other vectors - there are more advanced approaches that are much more efficient, like ANN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "257e0790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"and mortified bare arms\\n     Pins, wooden pricks, nails, sprigs of rosemary;\\n     And with this horrible object, from low farms, \\n     Poor pelting villages, sheepcotes, and mills,\\n     Sometime with lunatic bans, sometime with prayers,\\n     Enforce their charity. 'Poor Turlygod! poor Tom!'\\n     That's something yet! Edgar I nothing am.             Exit.\\n\\n\\n\\n\\nScene IV.\\nBefore Gloucester's Castle; Kent in the stocks.\\n\\nEnter Lear, Fool, and Gentleman.\\n\\n  Lear. 'Tis strange that they should so depart from home,\\n     And not send back my messenger.\\n  Gent. As I learn'd,\\n     The night before there was no purpose in them\\n     Of this remove.\\n  Kent. Hail to thee, noble master!\\n  Lear. Ha!\\n     Mak'st thou this shame thy pastime?\\n  Kent. No, my lord.\\n  Fool. Ha, ha! look! he wears cruel garters. Horses are tied by\\nthe\\n     head, dogs and bears by th' neck, monkeys by th' loins, and\\nmen\\n     by th' legs. When a man's over-lusty at legs, then he wears\\n     wooden nether-stocks.\\n  Lear. What's h\",\n",
       "  np.float64(0.5730843635540894)),\n",
       " (\"make them honours\\n     Of men's impossibility, have preserv'd thee.\\n  Glou. I do remember now. Henceforth I'll bear\\n     Affliction till it do cry out itself\\n     'Enough, enough,' and die. That thing you speak of,\\n     I took it for a man. Often 'twould say\\n     'The fiend, the fiend'- he led me to that place.\\n  Edg. Bear free and patient thoughts.\\n\\n         Enter Lear, mad, [fantastically dressed with weeds].\\n \\n     But who comes here?\\n     The safer sense will ne'er accommodate\\n     His master thus.\\n  Lear. No, they cannot touch me for coming;\\n     I am the King himself.\\n  Edg. O thou side-piercing sight!\\n  Lear. Nature 's above art in that respect. There's your press\\n     money. That fellow handles his bow like a crow-keeper. Draw\\nme\\n     a clothier's yard. Look, look, a mouse! Peace, peace; this\\npiece\\n     of toasted cheese will do't. There's my gauntlet; I'll prove\\nit\\n     on a giant. Bring up the brown bills. O, well flown, bird!\\ni'\\n     th' clout, i' th' clout! Hewgh! Give the \",\n",
       "  np.float64(0.5726671245898927)),\n",
       " (\"1606\\nTHE TRAGEDY OF KING LEAR\\n\\nby William Shakespeare\\n\\n\\n\\n\\nDramatis Personae\\n\\n      Lear, King of Britain.\\n      King of France.\\n      Duke of Burgundy.\\n      Duke of Cornwall.\\n      Duke of Albany.\\n      Earl of Kent.\\n      Earl of Gloucester.\\n      Edgar, son of Gloucester.\\n      Edmund, bastard son to Gloucester.\\n      Curan, a courtier.\\n      Old Man, tenant to Gloucester.\\n      Doctor.\\n      Lear's Fool.\\n      Oswald, steward to Goneril.\\n      A Captain under Edmund's command.\\n      Gentlemen.\\n      A Herald.\\n      Servants to Cornwall.\\n\\n      Goneril, daughter to Lear.\\n      Regan, daughter to Lear.\\n      Cordelia, daughter to Lear.\\n\\n      Knights attending on Lear, Officers, Messengers, Soldiers,\\n        Attendants.\\n\\n\\n\\n\\n<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\\nSHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\\nPROVIDED BY PROJECT GUTENBERG ETEXT OF CARNEGIE MELLON UNIVERSITY\\nWITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\\nDISTRIBUT\",\n",
       "  np.float64(0.5722186875554692))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.search_by_text(\"What is the climax on the KingLear story?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a9e1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-gpt",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
